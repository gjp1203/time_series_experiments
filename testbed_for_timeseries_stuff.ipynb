{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1D Convolutions Keras: Variable length input testing\n",
    "\n",
    "Tests were conducted using the UCR dataset https://www.cs.ucr.edu/~eamonn/time_series_data_2018/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv1D, Dense, GlobalMaxPooling1D, GlobalAveragePooling1D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical  \n",
    "from keras.models import Model, Sequential\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape(x):\n",
    "    return x.values.reshape((x.shape[0],x.shape[1],1))\n",
    "\n",
    "def tocat(y, num_classes):\n",
    "    return to_categorical(y, num_classes=num_classes)\n",
    "\n",
    "def getData(ds):\n",
    "    x_train = pd.read_csv('UCRArchive_2018/'+ds+'/'+ds+'_TRAIN.tsv', sep='\\t', header=None)\n",
    "    x_test  = pd.read_csv('UCRArchive_2018/'+ds+'/'+ds+'_TEST.tsv', sep='\\t', header=None)\n",
    "    y_train = x_train.pop(0)\n",
    "    y_test  = x_test.pop(0)\n",
    "    nc = max(y_test.max(), y_train.max())+1\n",
    "    return reshape(x_train), reshape(x_test), tocat(y_train, nc), tocat(y_test, nc), nc    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds1 = 'DiatomSizeReduction'\n",
    "ds2 = 'CinCECGTorso'\n",
    "\n",
    "x1_train, x1_test, y1_train, y1_test, num_classes = getData(ds1)\n",
    "x2_train, x2_test, y2_train, y2_test, num_classes = getData(ds2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 1.6095 - accuracy: 0.3125\n",
      "Epoch 2/25\n",
      "16/16 [==============================] - 0s 645us/step - loss: 1.5986 - accuracy: 0.3750\n",
      "Epoch 3/25\n",
      "16/16 [==============================] - 0s 499us/step - loss: 1.5870 - accuracy: 0.3750\n",
      "Epoch 4/25\n",
      "16/16 [==============================] - 0s 608us/step - loss: 1.5744 - accuracy: 0.3750\n",
      "Epoch 5/25\n",
      "16/16 [==============================] - 0s 579us/step - loss: 1.5614 - accuracy: 0.3750\n",
      "Epoch 6/25\n",
      "16/16 [==============================] - 0s 412us/step - loss: 1.5424 - accuracy: 0.3750\n",
      "Epoch 7/25\n",
      "16/16 [==============================] - 0s 522us/step - loss: 1.5255 - accuracy: 0.3750\n",
      "Epoch 8/25\n",
      "16/16 [==============================] - 0s 482us/step - loss: 1.5005 - accuracy: 0.3750\n",
      "Epoch 9/25\n",
      "16/16 [==============================] - 0s 470us/step - loss: 1.4811 - accuracy: 0.3750\n",
      "Epoch 10/25\n",
      "16/16 [==============================] - 0s 504us/step - loss: 1.4499 - accuracy: 0.3750\n",
      "Epoch 11/25\n",
      "16/16 [==============================] - 0s 448us/step - loss: 1.4264 - accuracy: 0.3750\n",
      "Epoch 12/25\n",
      "16/16 [==============================] - 0s 562us/step - loss: 1.3954 - accuracy: 0.3750\n",
      "Epoch 13/25\n",
      "16/16 [==============================] - 0s 475us/step - loss: 1.3722 - accuracy: 0.3750\n",
      "Epoch 14/25\n",
      "16/16 [==============================] - 0s 530us/step - loss: 1.3451 - accuracy: 0.3750\n",
      "Epoch 15/25\n",
      "16/16 [==============================] - 0s 419us/step - loss: 1.3228 - accuracy: 0.3750\n",
      "Epoch 16/25\n",
      "16/16 [==============================] - 0s 591us/step - loss: 1.3021 - accuracy: 0.3750\n",
      "Epoch 17/25\n",
      "16/16 [==============================] - 0s 535us/step - loss: 1.2950 - accuracy: 0.3750\n",
      "Epoch 18/25\n",
      "16/16 [==============================] - 0s 478us/step - loss: 1.2873 - accuracy: 0.3750\n",
      "Epoch 19/25\n",
      "16/16 [==============================] - 0s 667us/step - loss: 1.2822 - accuracy: 0.3750\n",
      "Epoch 20/25\n",
      "16/16 [==============================] - 0s 370us/step - loss: 1.2797 - accuracy: 0.3750\n",
      "Epoch 21/25\n",
      "16/16 [==============================] - 0s 552us/step - loss: 1.2843 - accuracy: 0.3750\n",
      "Epoch 22/25\n",
      "16/16 [==============================] - 0s 433us/step - loss: 1.2773 - accuracy: 0.3750\n",
      "Epoch 23/25\n",
      "16/16 [==============================] - 0s 604us/step - loss: 1.2797 - accuracy: 0.3750\n",
      "Epoch 24/25\n",
      "16/16 [==============================] - 0s 433us/step - loss: 1.2743 - accuracy: 0.3750\n",
      "Epoch 25/25\n",
      "16/16 [==============================] - 0s 504us/step - loss: 1.2718 - accuracy: 0.3750\n",
      "Evaluate\n",
      "306/306 [==============================] - 0s 551us/step\n",
      "Dataset 1: DiatomSizeReduction\n",
      "x1_train: (16, 345, 1) y1_train: (16, 5)\n",
      "{'accuracy': 0.3006536066532135, 'loss': 1.3978083287578782}\n",
      "1380/1380 [==============================] - 1s 858us/step\n",
      "Dataset 2: CinCECGTorso\n",
      "x2_train: (40, 1639, 1) y2_train: (40, 5)\n",
      "{'accuracy': 0.24782608449459076, 'loss': 1.61744545335355}\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv1D(filters=5, kernel_size=5, input_shape=(None, 1)))\n",
    "model.add(Conv1D(filters=5, kernel_size=5))\n",
    "model.add(Conv1D(filters=5, kernel_size=5))\n",
    "#model.add(GlobalMaxPooling1D())\n",
    "model.add(GlobalAveragePooling1D())\n",
    "model.add(Dense(1000, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(x1_train, y1_train, epochs=25, batch_size=10)\n",
    "print(\"Evaluate\")\n",
    "result = model.evaluate(x1_test, y1_test, batch_size=1)\n",
    "print(\"Dataset 1: \" + ds1)\n",
    "print(\"x1_train: \" + str(x1_train.shape) + \" y1_train: \" + str(y1_train.shape))\n",
    "print(dict(zip(model.metrics_names, result)))\n",
    "result = model.evaluate(x2_test, y2_test, batch_size=1, verbose=True)\n",
    "print(\"Dataset 2: \" + ds2)\n",
    "print(\"x2_train: \" + str(x2_train.shape) + \" y2_train: \" + str(y2_train.shape))\n",
    "print(dict(zip(model.metrics_names, result)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
